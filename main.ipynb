{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kamufalu 2.0 🏘️🪵🐖"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.txt', 'r') as file:\n",
    "    city_names = file.readlines()\n",
    "\n",
    "city_names = [line.strip() for line in city_names]\n",
    "\n",
    "longest = 0\n",
    "for i in range(len(city_names)):\n",
    "    if len(city_names[i]) > longest:\n",
    "        longest = len(city_names[i])\n",
    "\n",
    "sum = 0\n",
    "for i in range(len(city_names)):\n",
    "    sum = sum + len(city_names[1])\n",
    "\n",
    "print(city_names,\"\\nLongest:\",longest,\"\\nAverage\",sum/len(city_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Clean the data and convert to lowercase\n",
    "city_names = [name.lower() for name in city_names]\n",
    "\n",
    "# Step 2: Split city names into characters and create input-output pairs\n",
    "input_sequences = []\n",
    "output_sequences = []\n",
    "\n",
    "max_sequence_length = 10  # Example: Using input sequences of length 3\n",
    "\n",
    "for name in city_names:\n",
    "    #name = ' ' + name + ' '  # Add spaces at the beginning and end of the name\n",
    "    \n",
    "    # Using fixed maximum lenghts\n",
    "    for i in range(len(name) - max_sequence_length):\n",
    "        input_sequences.append(name[i:i+max_sequence_length])\n",
    "        output_sequences.append(name[i+max_sequence_length])\n",
    "\n",
    "    # Using variable lenghts\n",
    "    #for i in range(len(name) - 1):\n",
    "    #    input_sequences.append(name[:i+1])\n",
    "    #    output_sequences.append(name[i+1])\n",
    "\n",
    "# Print the input-output pairs\n",
    "#for i in range(len(input_sequences)):\n",
    "#    print('Input:', input_sequences[i], 'Output:', output_sequences[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 3: Vectorization\n",
    "characters = sorted(list(set(''.join(city_names))))  # Get unique characters and sort them\n",
    "char_to_index = {char: index for index, char in enumerate(characters)}\n",
    "\n",
    "num_chars = len(characters)\n",
    "\n",
    "# Convert input sequences to one-hot encoded vectors\n",
    "X = np.zeros((len(input_sequences), max_sequence_length, num_chars), dtype=np.float32)\n",
    "for i, sequence in enumerate(input_sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        X[i, t, char_to_index[char]] = 1.0\n",
    "\n",
    "# Convert output sequences to numerical labels\n",
    "y = np.zeros((len(output_sequences), num_chars), dtype=np.float32)\n",
    "for i, char in enumerate(output_sequences):\n",
    "    y[i, char_to_index[char]] = 1.0\n",
    "\n",
    "# Print the vectorized input-output pairs\n",
    "#for i in range(len(input_sequences)):\n",
    "#    print('Input:', X[i], 'Output:', y[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Step 4: Model Architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, input_shape=(max_sequence_length, num_chars)))\n",
    "model.add(Dense(units=num_chars, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Model Training\n",
    "batch_size = 120\n",
    "epochs = 50 # Sets iteration\n",
    "\n",
    "model.fit(X, y, batch_size=batch_size, epochs=epochs, validation_split=0.2, verbose=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Genetarion using Random Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Step 6: Model Generation\n",
    "seed_sequence = 'ku'  # Seed sequence for generating new city names\n",
    "generated_name_length = max_sequence_length-len(seed_sequence)+1  # Length of the generated city name\n",
    "\n",
    "# Generate characters one by one\n",
    "generated_name = seed_sequence\n",
    "for _ in range(generated_name_length):\n",
    "    x_pred = np.zeros((1, max_sequence_length, num_chars))\n",
    "    for t, char in enumerate(generated_name):\n",
    "        if char in char_to_index:\n",
    "            # print(char, \"and\", char_to_index[char])\n",
    "            x_pred[0, t, char_to_index[char]] = 1.0\n",
    "\n",
    "    # Predict the next character probabilities\n",
    "    predictions = model.predict(x_pred)[0]\n",
    "    predicted_index = np.random.choice(range(num_chars), p=predictions)\n",
    "\n",
    "    # Convert the predicted index back to a character\n",
    "    predicted_char = characters[predicted_index]\n",
    "\n",
    "    # Append the predicted character to the generated name\n",
    "    generated_name += predicted_char\n",
    "\n",
    "print(\"Generated Name:\", generated_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Genetarion using Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from Levenshtein import distance\n",
    "\n",
    "# Step 6: Model Generation\n",
    "seed_sequence = 'domb'  # Seed sequence for generating new city names\n",
    "generated_name_length = 10  # Length of the generated city name\n",
    "num_generated_names = 20  # Number of generated names\n",
    "\n",
    "generated_names = []\n",
    "\n",
    "for _ in range(num_generated_names):\n",
    "    generated_name = seed_sequence\n",
    "    while len(generated_name) < generated_name_length:\n",
    "        x_pred = np.zeros((1, len(generated_name), num_chars))\n",
    "        for t, char in enumerate(generated_name):\n",
    "            x_pred[0, t, char_to_index[char]] = 1.0\n",
    "\n",
    "        predictions = model.predict(x_pred, verbose=0)[0]\n",
    "        predicted_index = np.random.choice(range(num_chars), p=predictions)\n",
    "        predicted_char = characters[predicted_index]\n",
    "\n",
    "        generated_name += predicted_char\n",
    "\n",
    "    generated_names.append(generated_name)\n",
    "\n",
    "# Evaluate generated city names\n",
    "reference_names = city_names\n",
    "\n",
    "for generated_name in generated_names:\n",
    "    distances = [distance(generated_name, reference_name) for reference_name in reference_names]\n",
    "    average_distance = np.mean(distances)\n",
    "    print(f\"{generated_name} - LD: {average_distance}\")\n",
    "    # print(f\"Generated Name: {generated_name}, Average Levenshtein Distance: {average_distance}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
